{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factorization Machines in Spark\n",
    "Author: Gautam S. Muralidhar\n",
    "#### Reference: http://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf\n",
    "#### Spark Environment: Spark 1.6.1\n",
    "#### To run this notebook: \n",
    "PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First define a few helper functions that will help parse the data, originally in (user,item,rating) format, and convert it to a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function that parses a line in the data csv file and returns an array of (user, item, rating)\n",
    "# values\n",
    "def parseLine(line):\n",
    "    import numpy as np\n",
    "    (user,item,rating,ts)=line.split('\\t')\n",
    "    return np.array([int(user),int(item),float(rating)])\n",
    "\n",
    "# Function that returns a key-value pair, with key being the userid and value being 1\n",
    "def getUser(arr):\n",
    "    return (arr[0],1)\n",
    "\n",
    "# Function that returns a key-value pair, with key being the itemid and value being 1\n",
    "def getItem(arr):\n",
    "    return (arr[1],1)\n",
    "\n",
    "# Function that returns the rating for the given tuple\n",
    "def getRating(arr):\n",
    "    return arr[2]\n",
    "\n",
    "# Function that creates a feature vector from a (user,item,rating) tuple\n",
    "def createFMData(arr):\n",
    "    import numpy as np\n",
    "    all_users = usersBroadcastVar.value\n",
    "    all_items = itemsBroadcastVar.value\n",
    "    numusers = len(all_users)\n",
    "    numitems = len(all_items)\n",
    "    useridx = {}\n",
    "    itemidx = {}\n",
    "    \n",
    "    for i in range(0,numusers):\n",
    "        useridx[int(all_users[i])] = i\n",
    "    for i in range(0,numitems):\n",
    "        itemidx[int(all_items[i])] = i\n",
    "        \n",
    "    x = [0 for i in range(0,numusers+numitems+1)] # +1 is for the rating at the end\n",
    "    user_id = int(arr[0])\n",
    "    item_id = int(arr[1])\n",
    "    rating  = arr[2]\n",
    "    if useridx.has_key(user_id):\n",
    "        x[useridx[user_id]] = 1.0\n",
    "    if itemidx.has_key(item_id):\n",
    "        x[numusers+itemidx[item_id]] = 1.0\n",
    "    x[-1] = rating\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1\t5\t874965758\n",
      "1\t2\t3\t876893171\n",
      "1\t3\t4\t878542960\n",
      "1\t4\t3\t876893119\n",
      "1\t5\t3\t889751712\n",
      "1.0 5.0\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD based on the Training Data File\n",
    "trainingFileRdd = sc.textFile(\n",
    "                    \"/Users/gmuralidhar/Projects/MLDatasets/movielens-100k/ua.base\",\n",
    "                    minPartitions = 16, \n",
    "                    use_unicode = True\n",
    "                )\n",
    "for line in trainingFileRdd.take(5):\n",
    "  print line\n",
    "\n",
    "trainRdd = trainingFileRdd.map(parseLine)\n",
    "trainUsers = trainRdd.map(getUser).distinct().sortByKey().keys().collect()\n",
    "trainItems = trainRdd.map(getItem).distinct().sortByKey().keys().collect()\n",
    "minTrainRating = trainRdd.map(getRating).min()\n",
    "maxTrainRating = trainRdd.map(getRating).max()\n",
    "\n",
    "print minTrainRating, maxTrainRating\n",
    "usersBroadcastVar = sc.broadcast(trainUsers)\n",
    "itemsBroadcastVar = sc.broadcast(trainItems)\n",
    "\n",
    "# Create the Training Data RDD\n",
    "trainingData = trainRdd.map(createFMData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "[1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "print type(trainingData)\n",
    "oneExample = trainingData.take(1)[0]\n",
    "print oneExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t20\t4\t887431883\n",
      "1\t33\t4\t878542699\n",
      "1\t61\t4\t878542420\n",
      "1\t117\t3\t874965739\n",
      "1\t155\t2\t878542201\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD based on the Testing Data File\n",
    "testingFileRdd = sc.textFile(\n",
    "                    \"/Users/gmuralidhar/Projects/MLDatasets/movielens-100k/ua.test\",\n",
    "                    minPartitions = 16, \n",
    "                    use_unicode = True\n",
    "                )\n",
    "for line in testingFileRdd.take(5):\n",
    "  print line\n",
    "\n",
    "testRdd = testingFileRdd.map(parseLine)\n",
    "# Create the Training Data RDD\n",
    "testingData = testRdd.map(createFMData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "[1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "print type(testingData)\n",
    "oneExample = testingData.take(1)[0]\n",
    "print oneExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print trainingData.getNumPartitions()\n",
    "print testingData.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now implement the FM learning function.\n",
    "\n",
    "#### First define the function SGDUpdate that will be executed on the Spark executors. This is the function that will be used in a mapPartitions transformation on the training data RDD and called from the driver . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SGDUpdate(\n",
    "    iterator,\n",
    "    minRatingBroadcastVar, \n",
    "    maxRatingBroadcastVar, \n",
    "    paramsBroadcastVar,\n",
    "    weightsBroadcastVar\n",
    "):\n",
    "    import numpy as np\n",
    "    \n",
    "    def update_params_batch(\n",
    "            x,\n",
    "            y,\n",
    "            w_t,\n",
    "            n,\n",
    "            k,\n",
    "            miny,\n",
    "            maxy,\n",
    "            lambda0,\n",
    "            lambda1,\n",
    "            lambda2,\n",
    "            learning_rate,\n",
    "            b\n",
    "        ):\n",
    "            w0 = w_t[0]\n",
    "            w  = np.reshape(np.array(w_t[1:n+1]), (1,n))\n",
    "            v  = np.matrix(np.reshape(w_t[n+1:],(n,k)))\n",
    "\n",
    "            y_hat = predict(x,w0,w,v)\n",
    "            y_hat = np.minimum(maxy, y_hat)\n",
    "            y_hat = np.maximum(miny, y_hat)\n",
    "            term1 = 2*(y_hat - y)\n",
    "\n",
    "            gradw0 = np.sum(term1, axis = 0) + lambda0*w0\n",
    "            \n",
    "            if(gradw0.shape[0] <> 1 or gradw0.shape[1] <> 1):\n",
    "                raise ValueError('Gradient w0 has more than 1 element')\n",
    "            gradw = np.sum(np.multiply(term1,x), axis = 0) + lambda1*w\n",
    "            if(gradw.shape[1] <> x.shape[1]):\n",
    "                raise ValueError('Gradient w has incorrect number of elements')   \n",
    "            gradv = np.zeros(v.shape)\n",
    "            d = x.shape[0]\n",
    "            instances = range(0,d)\n",
    "            for dd in instances:\n",
    "                xd = x[dd,:]\n",
    "                xdv = xd*v\n",
    "                gradv += term1[dd][0,0] * (\n",
    "                            np.multiply(xd.T,np.repeat(xdv,xd.shape[1],axis=0)) -\n",
    "                            np.multiply(v,np.square(xd.T))\n",
    "                        ) \n",
    "            gradv += lambda2*v\n",
    "\n",
    "            w0 -= (learning_rate/b*1.0)*gradw0\n",
    "            w  -= (learning_rate/b*1.0)*gradw\n",
    "            v  -= (learning_rate/b*1.0)*gradv\n",
    "            return [w0[0,0]] + w[0,:].tolist() + np.array(np.reshape(v,(1,n*k))).tolist()[0]\n",
    "    \n",
    "    def update_params(\n",
    "            x,\n",
    "            y,\n",
    "            w_t,\n",
    "            n,\n",
    "            k,\n",
    "            miny,\n",
    "            maxy,\n",
    "            lambda0,\n",
    "            lambda1,\n",
    "            lambda2,\n",
    "            learning_rate\n",
    "        ):\n",
    "            w0 = w_t[0]\n",
    "            w  = np.reshape(np.array(w_t[1:n+1]),(1,n))\n",
    "            v  = np.matrix(np.reshape(w_t[n+1:],(n,k)))\n",
    "\n",
    "            y_hat = predict(x,w0,w,v)\n",
    "            y_hat = np.minimum(maxy, y_hat)\n",
    "            y_hat = np.maximum(miny, y_hat)\n",
    "            term1 = 2*(y_hat - y)\n",
    "            gradw0 = term1 + lambda0*w0\n",
    "            if(gradw0.shape[0] <> 1 or gradw0.shape[1] <> 1):\n",
    "                raise ValueError('Gradient w0 has more than 1 element')\n",
    "            gradw = np.multiply(term1,x) + lambda1*w\n",
    "            if(gradw.shape[1] <> x.shape[1]):\n",
    "                raise ValueError('Gradient w has incorrect number of elements')   \n",
    "            gradv = np.zeros(v.shape)\n",
    "            xdv = x*v\n",
    "            gradv += term1[0,0] * (\n",
    "                        np.multiply(x.T,np.repeat(xdv,x.shape[1],axis=0)) -\n",
    "                        np.multiply(v,np.square(x.T))\n",
    "                    ) \n",
    "            gradv += lambda2*v\n",
    "            w0 -= learning_rate*gradw0\n",
    "            w  -= learning_rate*gradw\n",
    "            v  -= learning_rate*gradv\n",
    "            return [w0[0,0]] + w[0,:].tolist() + np.array(np.reshape(v,(1,n*k))).tolist()[0]\n",
    "    \n",
    "    def predict(x, w0, w, v):\n",
    "        return (w0 + \n",
    "            x*w.T + \n",
    "            0.5*(np.sum(np.square(x*v) - (np.square(x)*np.square(v)),axis=1))\n",
    "        )\n",
    "    \n",
    "    miny = minRatingBroadcastVar.value\n",
    "    maxy = maxRatingBroadcastVar.value\n",
    "    parameters = paramsBroadcastVar.value\n",
    "    \n",
    "    lambda0 = parameters[0]\n",
    "    lambda1 = parameters[1]\n",
    "    lambda2 = parameters[2]\n",
    "    learning_rate = parameters[3]\n",
    "    n = int(parameters[4])\n",
    "    k = int(parameters[5])\n",
    "    random_seed = parameters[6]\n",
    "    \n",
    "    mat = np.matrix(list(iterator),dtype=float)\n",
    "    x = mat[:,0:n]\n",
    "    y = np.array(mat[:,n],dtype=float)\n",
    "    d = x.shape[0]\n",
    "    \n",
    "    minibatch_size = 300\n",
    "    indx = range(0,d)\n",
    "    if (random_seed != 'None'):\n",
    "        random_seed = int(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    w_t = np.array(weightsBroadcastVar.value)\n",
    "    if (d >= 600):\n",
    "        shuffledindx = np.random.permutation(indx)\n",
    "        start = 0;\n",
    "        end = minibatch_size\n",
    "        while (start < d):\n",
    "            xbatch = x[shuffledindx[start:end],:]\n",
    "            ybatch = y[shuffledindx[start:end]]\n",
    "            w_t = update_params_batch(\n",
    "                        xbatch,\n",
    "                        ybatch,\n",
    "                        w_t,\n",
    "                        n,\n",
    "                        k,\n",
    "                        miny,\n",
    "                        maxy,\n",
    "                        lambda0,\n",
    "                        lambda1,\n",
    "                        lambda2,\n",
    "                        learning_rate,\n",
    "                        xbatch.shape[0]\n",
    "                )\n",
    "            start += minibatch_size\n",
    "            end += minibatch_size\n",
    "            if (end > d):\n",
    "                end = d\n",
    "    else:\n",
    "        shuffledindx = np.random.permutation(indx)\n",
    "        for i in shuffledindx:\n",
    "            xd = x[i,:]\n",
    "            yd = y[i]\n",
    "            w_t = update_params(\n",
    "                        xd,\n",
    "                        yd,\n",
    "                        w_t,\n",
    "                        n,\n",
    "                        k,\n",
    "                        miny,\n",
    "                        maxy,\n",
    "                        lambda0,\n",
    "                        lambda1,\n",
    "                        lambda2,\n",
    "                        learning_rate\n",
    "                )\n",
    "    return w_t\n",
    "    # If reduceByKey is called on mapPartitions, then return the tuple below.\n",
    "    #wt_indx = range(0,n+(n*k)+1)\n",
    "    #return zip(wt_indx,w_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will create the driver function called fm_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fm_fit(\n",
    "    trainingDataRdd,\n",
    "    minRating,\n",
    "    maxRating,\n",
    "    params\n",
    "):\n",
    "    import numpy as np\n",
    "    from functools import partial\n",
    "    from operator import add\n",
    "\n",
    "    lambda0 = 1\n",
    "    lambda1 = 1\n",
    "    lambda2 = 1\n",
    "    n_iter = 100\n",
    "    learning_rate = 1\n",
    "    k = 10\n",
    "    random_seed = 'None'\n",
    "    \n",
    "    if params is not None and len(params) != 0:\n",
    "        if params.has_key('lambda0'):\n",
    "            lambda0 = float(params['lambda0'])\n",
    "        if params.has_key('lambda1'):\n",
    "            lambda1 = float(params['lambda1'])\n",
    "        if params.has_key('lambda2'):\n",
    "            lambda2 = float(params['lambda2'])\n",
    "        if params.has_key('n_iter'):\n",
    "            n_iter = int(params['n_iter'])\n",
    "        if params.has_key('learning_rate'):\n",
    "            learning_rate = float(params['learning_rate'])\n",
    "        if params.has_key('k'):\n",
    "            k = int(params['k'])\n",
    "        if params.has_key('random_seed'):\n",
    "            random_seed = int(params['random_seed'])\n",
    "    \n",
    "    n = len(trainingDataRdd.take(1)[0])-1\n",
    "    \n",
    "    parameters = [lambda0,lambda1,lambda2,learning_rate,n,k,random_seed]\n",
    "\n",
    "    w0 = 0\n",
    "    w = np.zeros([1,n])\n",
    "    v = np.random.normal(scale=0.1,size=(n,k))\n",
    "    w_t = [w0] + w[0,:].tolist() + np.array(np.reshape(v,(1,n*k))).tolist()[0]\n",
    "\n",
    "    paramsBroadcastVar    = sc.broadcast(parameters)\n",
    "    minRatingBroadcastVar = sc.broadcast(minRating)\n",
    "    maxRatingBroadcastVar = sc.broadcast(maxRating)\n",
    "\n",
    "    for i in range(0,n_iter):\n",
    "        print 'Epoch number: ' + str(i)\n",
    "        weightsBroadcastVar = sc.broadcast(w_t)\n",
    "        weights = trainingDataRdd.mapPartitions(partial(\n",
    "                                                SGDUpdate,\n",
    "                                                minRatingBroadcastVar=minRatingBroadcastVar,\n",
    "                                                maxRatingBroadcastVar=maxRatingBroadcastVar,\n",
    "                                                paramsBroadcastVar=paramsBroadcastVar,\n",
    "                                                weightsBroadcastVar=weightsBroadcastVar\n",
    "                                              )\n",
    "                                          ).glom().collect() \n",
    "        w_t = np.matrix(weights)\n",
    "        w_t = np.mean(w_t,axis=0)\n",
    "        w_t = w_t.tolist()[0]\n",
    "        # Alternately, can have mapPartitions return a tuple of (indx,wt) and use reduceByKey\n",
    "        # If using reduceByKey, your final wts are averaged as below\n",
    "        #w_t = np.array([v for k, v in weights])\n",
    "        #w_t = w_t/trainingDataRdd.getNumPartitions()\n",
    "        #w_t  = w_t.tolist()\n",
    "    return w_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the driver function to train the FM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0\n",
      "Epoch number: 1\n",
      "Epoch number: 2\n",
      "Epoch number: 3\n",
      "Epoch number: 4\n",
      "Epoch number: 5\n",
      "Epoch number: 6\n",
      "Epoch number: 7\n",
      "Epoch number: 8\n",
      "Epoch number: 9\n",
      "Epoch number: 10\n",
      "Epoch number: 11\n",
      "Epoch number: 12\n",
      "Epoch number: 13\n",
      "Epoch number: 14\n",
      "Epoch number: 15\n",
      "Epoch number: 16\n",
      "Epoch number: 17\n",
      "Epoch number: 18\n",
      "Epoch number: 19\n",
      "Epoch number: 20\n",
      "Epoch number: 21\n",
      "Epoch number: 22\n",
      "Epoch number: 23\n",
      "Epoch number: 24\n",
      "Epoch number: 25\n",
      "Epoch number: 26\n",
      "Epoch number: 27\n",
      "Epoch number: 28\n",
      "Epoch number: 29\n",
      "Epoch number: 30\n",
      "Epoch number: 31\n",
      "Epoch number: 32\n",
      "Epoch number: 33\n",
      "Epoch number: 34\n",
      "Epoch number: 35\n",
      "Epoch number: 36\n",
      "Epoch number: 37\n",
      "Epoch number: 38\n",
      "Epoch number: 39\n",
      "Epoch number: 40\n",
      "Epoch number: 41\n",
      "Epoch number: 42\n",
      "Epoch number: 43\n",
      "Epoch number: 44\n",
      "Epoch number: 45\n",
      "Epoch number: 46\n",
      "Epoch number: 47\n",
      "Epoch number: 48\n",
      "Epoch number: 49\n",
      "Epoch number: 50\n",
      "Epoch number: 51\n",
      "Epoch number: 52\n",
      "Epoch number: 53\n",
      "Epoch number: 54\n",
      "Epoch number: 55\n",
      "Epoch number: 56\n",
      "Epoch number: 57\n",
      "Epoch number: 58\n",
      "Epoch number: 59\n",
      "Epoch number: 60\n",
      "Epoch number: 61\n",
      "Epoch number: 62\n",
      "Epoch number: 63\n",
      "Epoch number: 64\n",
      "Epoch number: 65\n",
      "Epoch number: 66\n",
      "Epoch number: 67\n",
      "Epoch number: 68\n",
      "Epoch number: 69\n",
      "Epoch number: 70\n",
      "Epoch number: 71\n",
      "Epoch number: 72\n",
      "Epoch number: 73\n",
      "Epoch number: 74\n",
      "Epoch number: 75\n",
      "Epoch number: 76\n",
      "Epoch number: 77\n",
      "Epoch number: 78\n",
      "Epoch number: 79\n",
      "Epoch number: 80\n",
      "Epoch number: 81\n",
      "Epoch number: 82\n",
      "Epoch number: 83\n",
      "Epoch number: 84\n",
      "Epoch number: 85\n",
      "Epoch number: 86\n",
      "Epoch number: 87\n",
      "Epoch number: 88\n",
      "Epoch number: 89\n",
      "Epoch number: 90\n",
      "Epoch number: 91\n",
      "Epoch number: 92\n",
      "Epoch number: 93\n",
      "Epoch number: 94\n",
      "Epoch number: 95\n",
      "Epoch number: 96\n",
      "Epoch number: 97\n",
      "Epoch number: 98\n",
      "Epoch number: 99\n"
     ]
    }
   ],
   "source": [
    "w_t = fm_fit(\n",
    "    trainingData,\n",
    "    minTrainRating,\n",
    "    maxTrainRating,\n",
    "    {'lambda0':0.01,'lambda1':0.01,'lambda2':0.02,\n",
    "         'k':10, 'n_iter':100, 'learning_rate':0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now implement the prediction function\n",
    "#### First, create the predict_example function that will be executed on the Spark executors. This is the function that will be used in a map transformation on the testing data RDD and called from the driver . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_example(\n",
    "    arr,\n",
    "    minRatingBroadcastVar, \n",
    "    maxRatingBroadcastVar, \n",
    "    weightsBroadcastVar,\n",
    "    nBroadcastVar,\n",
    "    kBroadcastVar\n",
    "    \n",
    "):\n",
    "    import numpy as np\n",
    "    miny = minRatingBroadcastVar.value\n",
    "    maxy = maxRatingBroadcastVar.value\n",
    "    w_t  = weightsBroadcastVar.value\n",
    "    n    = nBroadcastVar.value\n",
    "    k    = kBroadcastVar.value\n",
    "    \n",
    "    x = np.matrix(arr[0:n], dtype=float)\n",
    "    w0 = w_t[0]\n",
    "    w  = np.reshape(np.array(w_t[1:n+1]),(1,n))\n",
    "    v  = np.matrix(np.reshape(w_t[n+1:],(n,k)))\n",
    "    y_hat = (w0 + \n",
    "            x*w.T + \n",
    "            0.5*(np.sum(np.square(x*v) - (np.square(x)*np.square(v)),axis=1))\n",
    "           )\n",
    "\n",
    "    y_hat = np.minimum(maxy, y_hat)\n",
    "    y_hat = np.maximum(miny, y_hat)\n",
    "    return [arr[n],y_hat[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will create the driver function called fm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fm_predict(\n",
    "    testingDataRdd,\n",
    "    w_t,\n",
    "    k,\n",
    "    minRating,\n",
    "    maxRating\n",
    "):\n",
    "    import numpy as np\n",
    "    from functools import partial\n",
    "    \n",
    "    n = len(testingDataRdd.take(1)[0])-1\n",
    "    minRatingBroadcastVar = sc.broadcast(minRating)\n",
    "    maxRatingBroadcastVar = sc.broadcast(maxRating)\n",
    "    weightsBroadcastVar   = sc.broadcast(w_t)\n",
    "    nBroadcastVar         = sc.broadcast(n)\n",
    "    kBroadcastVar         = sc.broadcast(k)\n",
    "    \n",
    "    predictions = testingDataRdd.map(partial(\n",
    "                                    predict_example,\n",
    "                                    minRatingBroadcastVar=minRatingBroadcastVar,\n",
    "                                    maxRatingBroadcastVar=maxRatingBroadcastVar,\n",
    "                                    weightsBroadcastVar=weightsBroadcastVar,\n",
    "                                    nBroadcastVar=nBroadcastVar,\n",
    "                                    kBroadcastVar=kBroadcastVar\n",
    "                                    )\n",
    "                                ).collect()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the prediction driver function and compute MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = fm_predict(\n",
    "    testingData,\n",
    "    w_t,\n",
    "    10,\n",
    "    minTrainRating,\n",
    "    maxTrainRating\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error = 0.964102916613\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = np.matrix(predictions)\n",
    "y_test = predictions[:,0]\n",
    "y_hat = predictions[:,1]\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test,y_hat)\n",
    "print (\"Mean squared error = \" + str(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
